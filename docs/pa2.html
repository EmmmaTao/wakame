<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Wakame: Programming Assignment 2</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Le styles -->    
    <link href="css/bootstrap.css" rel="stylesheet">
    <link href="css/cs6640.css" rel="stylesheet">
    <link href="js/google-code-prettify/prettify.css" type="text/css" rel="stylesheet" />    

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

  </head>

  <body data-spy="scroll" data-target="#navbar" body onload="prettyPrint()">

    <nav id="navbar" class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">PA2</a>
        </div>
        <div class="collapse navbar-collapse">
          <ul class="nav navbar-nav">            
            <li class="active"><a href="#prelim">Preliminaries</a></li>
            <li><a href="#p1">Part 1</a></li>
            <li><a href="#p2">Part 2</a></li>
            <li><a href="#p3">Part 3</a></li>
            <li><a href="#p4">Part 4</a></li>
          </ul>          
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container" id="main">

      \(
       \def\bold#1{\boldsymbol{#1}}
       \def\vp{p}
       \def\vr{r}
       \def\integrand{\mathcal{F}}
       \def\dee{\mathrm{d}}       
      \)

      <h1 id="head1">Programming Assignment 2 <span class="subtitle">Monte Carlo Tracings</span></h1>

      <a href="#" id="prelim"></a>
      <h2>Preliminaries</h2>      

      <p>In this programming assignment, you will be implementing various flavors of didrect illumination integrators with different sampling distributions.  You also will add new kinds of emitters with finite extent (i.e. not point sources) and two new BSDFs.  Lastly, you will implement a path tracer that computes full globall illumination in the scene.</p>

      <p>Like in the first assignment, we don't explicitly specify an API that you should use to implement the sampling and evaluation operations for emittersâ€”finding suitable abstractions is part of the exercise. That said, you can look at the BSDF definitions in the <code>wakame.bsdf.Bsdf</code> class to get a rough idea as to how one might get started with such an interface. </p>

      <p>Start by porting the code you wrote for PA1 to the <tt>pa2</tt> directory in the repository.</p>

      <a href="#" id="p1"></a>
      <h2>Part 1: Light Sampling</h2>

      <h3>Part 1.1: Integrator Implementation</h3>

      <p>In this part you will implement a new direct illumination integrator (<tt>direct_ems</tt>) which can integrate incident radiance by performing emitter sampling.  In addition to point lights, this integrator will be able to handle three additional types of emitters: distant disk lights, and mesh (area) lights.  These new emitters can be fully, partially or not at all visible from a point in your scene, so you will perform Monte Carlo integration to compute reflected radiance (accounting also for visibility) at your first camera intersection.</p>

      <p>The integrator willl compute the <em>local illumination integral</em>:
        \[
          L_o (\vp,\omega_o) = L_e(\vp,\omega_o) + \int_{H^2} f_r (\vp,\omega_o,\omega_i)\,L_i (\vp,\omega_i)\cos \theta_i \, \mathrm{d} \omega_i.
        \]
        where \(f_r\) is the BRDF, \(p\) is a surface position and \(L_i\) and \(L_o\) denote the incident and outgoing radiance functions.
        Generally, \(L_i\) and \(L_o\) are related to each other using the ray tracing operator
        \(\vr(p, \omega)\), which returns the nearest surface position visible along the ray \((\vp, \omega)\), i.e.
        \[
          L_i(\vp,\omega)=L_o(\vr(\vp, \omega), -\omega)
        \]
        and the above integral is thus defined recursively. Up to Part 3, we focus on <em>direct illumination</em>
        only and therefore truncate the recursion after the first light bounce. This means that the integral is now given by
        \[
        L_o (\vp,\omega_o) = L_e(\vp,\omega_o) + \int_{H^2} \underbrace{f_r (\vp,\omega_o,\omega_i)\,L_e (\vr(\vp,\omega_i), -\omega_i) \cos \theta_i}_{=: \integrand(\vp, \omega_o, \omega_i)} \, \mathrm{d} \omega_i.
        \]
        We set \(\integrand(\vp, \omega_o, \omega_i)\) as the integrand in the above expression to simplify the notation below.
      </p>

      <p>In comparison to the last assignment, we will be be working with emitters that have a finite extent, which means that they can be directly observed by the camera. This is why the first summand in the above equation is needed: it returns emitted radiance towards the camera when light sources are visible on screen.  Also note that the above equation defines outgoing radiance at surface points. To visualize incident radiance at the camera, you will need one more invocation of the ray tracing operator.</p>


      <p>For this part, you will distribute your samples for the new emitters according to an emitter specific density function \(\text{pdf}_\text{em}\):
      \[
        L_o (p,\omega_o) \approx \frac{1}{N} \sum_{k=1}^N \left( L_e(p,\omega_o) + \frac{\integrand\left(p,\omega_o,\omega_i^{(k)}\right)}{\text{pdf}_{\text{em}}\left(\omega_i^{(k)}\right)} \right)\\
      \]
      where $N$ is the number of samples per pixel, and $\omega_i^{(k)}$ is the light incoming direction sampled while evaluating the $k$th pixel sample.  The $\text{pdf}_\text{em}$ distribution can be constructed by choosing an emitter uniformly at random and then sampling a direction to the chosen light source.
      </p>

      <h3>Part 1.2: Distant Disk Light</h3>

      <p>There can be at most one distant disk emitter per scene, and it cannot coexist with an environment emitter. (You will implement one in the next PA.)  When present, it is fully specified by its radiance, a <tt>toWorld</tt> transformation and the angle subtended by the light source as seen by object in the scene when there is no occlusion \(\theta_a \in [0^\circ,180^\circ]\). For a values of \(\theta_a \to 0\) the emitter tends to a directional light source and for a value of \(\theta_a = 180\) the emitter is a constant spherical environment map. In addition the emitter can be rotated using a <tt>toWorld</tt> transformation. You can safely assume that only rotations are allowed as transformations for this emitter. When no transformation is given (i.e <tt>toWorld</tt> \(= \bold{I} \)) then the subtended angle is measured (in degrees) from the Z-axis \([0,0,1]\). Here is how instances of <tt>distantdisk</tt> will be specified in Wakame's scene description language:</p>

      <pre class="prettyprint linenums lang-xml">&lt;scene&gt;
    &lt;!-- Define a distant disk emitter --&gt;
    &lt;emitter type="distantdisk"&gt;
        &lt;!-- Set the radiance to a 60 W/m<sup>2</sup>sr  for all channels --&gt;
        &lt;color name="radiance" value="60"/&gt;

        &lt;!-- Set the subtended angle to 5 degrees --&gt;
        &lt;float name="thetaA" value="5"/&gt;

        &lt;!-- Rotate the disk 30 degrees counter-clockwise around the Y-axis --&gt;
        &lt;transform name="toWorld"/&gt;
            &lt;rotate axis="0,1,0" value="30"/&gt;
        &lt;/transform&gt;
    &lt;/emitter&gt;
    &lt;!-- ..... --&gt;
&lt;/scene&gt;</pre>

      <h4>Radiance Evaluation</h4>

      <p>In your <code>DistantDisk</code> class, implement a method which will be called whenever a ray escapes your scene or when doing shadow connections. After transforming \(\bold{\omega_i}\) to the emitters local coordinate system, this method will return the constant radiance value when the angle from Z-axis is less or equal than \(\theta_a\) and zero otherwise. Remember to convert your angles to radians before using the standard trigonometric functions. Here is a usage example for the world-to-local and local-to-world transformations:
      </p>

          <div class="row">
            <div class="col-md-6">
              <pre class="prettyprint linenums lang-java" >
// setProperties(HashMap&lt;String, Object&gt; properties) Example

/* Read a toWorld transform from the XML scene
   specification. If not present, use the identity */
emitterToWorld.set(PropertiesUtil.getTransform(properties, 
   "toWorld", Transform());

/* Invert the toWorld transformation */
worldToEmitter.invert(emitterToWorld);

//...</pre>
            </div>

            <div class="col-md-6">
              <pre class="prettyprint linenums ">
// Usage Example

/* Convert a world space direction to
   a local direction and vice versa    */

Vector3d d1Local = new Vector3d();
worldToEmitter.m.transform(d1World, d1Local);

Vector3d d2World = new Vector3d();
emitterToWorld.m.transform(d2Local, d2World);

//...</pre>
            </div>
          </div>

      <h4>Sampling and Density</h4>

      <p>Implement a method for generating a world space direction uniformly over the subtended solid angle of the distant disk light. You might find <code>Warp.squareToUniformSphericalCap</code> and your <tt>toWorld</tt> transformations useful. Implement another method which returns the probability density of the sampling method for a given a world space direction.</p>      

      <h3>Part 1.3: Mesh Area Light</h3>

      <p>Implement the <code>AreaEmitter</code> class, which represents a mesh area light source.  It must be attached to a mesh and emits radiance uniformly in all directions from each triangle of the mesh. It is parametrized by radiance. Here is how instances of area emitters will be specified in Wakame's scene description language:</p>

      <pre class="prettyprint linenums lang-xml">&lt;scene&gt;
    &lt;!-- Load a Wavefront OBJ file named "mesh.obj" --&gt;
    &lt;mesh type="obj"&gt;
        &lt;string name="filename" value="mesh.obj"/&gt;

        &lt;!-- Turn the mesh into an area light source --&gt;
        &lt;emitter type="area"&gt;
            &lt;!-- Assign a uniform radiance of 1 W/m<sup>2</sup>sr --&gt;
            &lt;color name="radiance" value="1,1,1"/&gt;
        &lt;/emitter&gt;
    &lt;/mesh&gt;

    &lt;!-- ..... --&gt;
&lt;/scene&gt;</pre>

      <h4>Radiance Evaluation</h4>

      <p>In your <code>AreaEmitter</code> class implement a method which can be called by the integrators whenever a ray intersects your mesh emitter. Given a camera ray intersection point \(p_c\) with an emitter this function should return the associated radiance value when the front side of an emissive triangle was intersected and zero otherwise.  This method (or a separate one) should also be able to return the radiance of points on the emitter that are not directly seen by the camera (ignoring occlusion for now), which will be needed for direct illumination sampling.</p>

      <h4>Mesh Sampling and Density</h4>

      <p>Familiarize yourself with the <code>wakame.mesh.Mesh</code> class to see how vertices, faces and normals are stored. In this class, implement a method that uniformly samples positions on the surface and also computes the corresponding normal. Additionally implement a method that returns the density function of your importance sampling technique.</p>

      <p> You can perform your sampling by first choosing a triangle from the mesh according to its area, and then sampling uniformly within that triangle. Interpolate the vertex normals when they are provided or compute the normal to the plane defined by the corresponding triangle otherwise. You may find the <code>wakame.util.DiscretePDF</code> class useful. For efficiency, build a discrete PDF over triangles once when the <code>activate()</code> method of the <code>Mesh</code> is called, and use this precomputed data in your sampling code.</p>

      <h4>Direction Sampling and Density</h4>

      <p>With the help of your sampling and density methods implemented in the <code>Mesh</code> class, implement the corresponding sampling methods in your area emitter. Your density evaluation method takes as input a world space direction (along with the corresponding sampled position and normal on your emitter) generated using your sampling method returns the probability density used when converted to solid angle measure. Make sure to return zero whenever a back facing triangle is encountered.</p>

      <h3>Part 1.4: Validation</h3>

      <p>
        Pass the the <tt>direct_ems</tt> related tests found in <tt>data/pa2/tests</tt>: 
        <ul> 
          <li> first 4 t-tests in <tt>test-distant.xml</tt>, </li>
          <li> first 5 tests in <tt>test-mesh.xml</tt>, </li>
          <li> first 2 tests in <tt>test-mesh-furnace.xml</tt> </li>
        </ul>
      </p>
      <p>
        Using <tt>direct_ems</tt> render the following scenes found in <tt>data/pa2</tt> : 
        <ul>
          <li><tt>sphere/sphere_ao_ems.xml</tt>, </li>
          <li><tt>sphere/sphere_side_ems.xml</tt>, </li>
          <li><tt>odyssey/odyssey_ems.xml</tt></li>
        </ul>
      </p>

      <table class="table table-bordered">
        <tr>
          <td align="center" valign="center"><a href="images/pa2/sphere_ao_ems_256spp.png"><img src="images/pa2/sphere_ao_ems_256spp.png" height="200"/></a></td>
          <td align="center" valign="center"><a href="images/pa2/sphere_side_ems_256spp.png"><img src="images/pa2/sphere_side_ems_256spp.png" height="200"/></a></td>
          <td align="center" valign="center"><a href="images/pa2/odyssey_ems_64spp.png"><img src="images/pa2/odyssey_ems_64spp.png" height="200"/></a></td>          
        </tr>
        <tr>
          <td align="center"><tt>sphere/sphere_ao_ems.xml</tt></td>
          <td align="center"><tt>sphere/sphere_side_ems.xml</tt></td>
          <td align="center"><tt>odyssey/odyssey_ems.xml</tt></td>          
        </tr>
      </table>

      <a href="#" id="p2"></a>
      <h2>Part 2: BRDF Sampling</h2>

      <h3>Part 2.1: Integrator Implementation</h3>

      <h4>Evaluation</h4>

      <p>In this part we will implement a new direct illumination integrator (<tt>direct_mats</tt>) that can integrate incident radiance from mesh lights and distant disk lights. In addition you will implement a new microfacet BRDF. For this part of the assignment you will distribute your samples according to a BRDF specific density function :
      \[
      L_o (p,\omega_o) \approx \frac{1}{N} \sum_{k=1}^N \left( L_e(p,\omega_o) + \frac{\integrand(p,\omega_o,\omega_i^{(k)})}{\text{pdf}_{\text{mat}}\big(\omega_i^{(k)}\big)} \right)
      \]
      This integrator should produce black images with zero-valued pixels when given a scene containing only point lights, since the probability of intersecting them with this sampling strategy is zero.</p>

      <h4>Validation</h4>

      <p>
        Pass the the <tt>direct_mats</tt> related tests found in <tt>data/pa2/tests</tt>: 
        <ul> 
          <li> the second 4 t-tests in <tt>test-distant.xml</tt>, </li>
          <li> the second 5 tests in <tt>test-mesh.xml</tt>, </li>
          <li> the second 2 tests in <tt>test-mesh-furnace.xml</tt> </li>
        </ul>
      </p>
      <p>
        Using <tt>direct_ems</tt> render the following scenes found in <tt>data/pa2</tt> : 
        <ul>
          <li><tt>sphere/sphere_ao_mats.xml</tt>, </li>
          <li><tt>sphere/sphere_side_mats.xml</tt>, </li>
          <li><tt>odyssey/odyssey_mats.xml</tt></li>
        </ul>
      </p>

      <table class="table table-bordered">
        <tr>
          <td align="center" valign="center"><a href="images/pa2/sphere_ao_mats_256spp.png"><img src="images/pa2/sphere_ao_mats_256spp.png" height="200"/></a></td>
          <td align="center" valign="center"><a href="images/pa2/sphere_side_mats_256spp.png"><img src="images/pa2/sphere_side_mats_256spp.png" height="200"/></a></td>
          <td align="center" valign="center"><a href="images/pa2/odyssey_mats_64spp.png"><img src="images/pa2/odyssey_mats_64spp.png" height="200"/></a></td>          
        </tr>
        <tr>
          <td align="center"><tt>sphere/sphere_ao_mats.xml</tt></td>
          <td align="center"><tt>sphere/sphere_side_mats.xml</tt></td>
          <td align="center"><tt>odyssey/odyssey_mats.xml</tt></td>          
        </tr>
      </table>   

      <h3>Part 2.2: Microfacet BRDF</h3>

      <p>The Microfacet BRDF you will implement for this part is a simple linear blend between a diffuse BRDF and a rough dielectric microfacet BRDF. Implement <code>Microfacet.eval()</code> which evaluates the described microfacet BRDF for a given pair of directions in local frame:
      \[
        f_r(\bold{\omega_i},\bold{\omega_o}) = \frac{k_d}{\pi} + {k_s} \frac{D(\bold{\omega_{h}})~
        F\left({(\bold{\omega_h} \cdot \bold{\omega_i})}, \eta_{e},\eta_{i}\right)~
        G(\bold{\omega_i},\bold{\omega_o},\bold{\omega_{h}})}{4 \cos{\theta_i} \cos{\theta_o}}, ~~
        \bold{\omega_{h}} = \frac{\left(\bold{\omega_i} + \bold{\omega_o}\right)}{\left|\left|\bold{\omega_i} + \bold{\omega_o}\right|\right|_2}
      \]
      where \(k_d \in [0,1]^3\) is the RGB diffuse reflection coefficient, \(k_s = 1 - \max(k_d)\), \(F\) is the fresnel reflection coefficient, \(\eta_e\) is the exterior index of refraction and \(\eta_i\) is the interior index of refraction. The distribution function \(D\) is the Beckmann distribution:

      \[
        D(\bold{\omega_{h}}) = \frac{e^{\frac{-\tan^2{\theta_{h}}}{\alpha^2}}}{\pi\, \alpha^2 \cos^4 \theta_{h} }

      \]
      with its corresponding shadowing term approximation (Smith):      
      \begin{align*}
        G(\bold{\omega_i},\bold{\omega_o},\bold{\omega_{h}}) 
        &= G_1(\bold{\omega_i},\bold{\omega_{h}})~G_1(\bold{\omega_o},\bold{\omega_{h}})\\
        G_1(\bold{\omega_v},\bold{\omega_h}) 
        &= \chi^+\left(\frac{\bold{\omega_v}\cdot\bold{\omega_h}}{\bold{\omega_v}\cdot\bold{n}}\right)
        \begin{cases}
          \frac{3.535b+2.181b^2}{1+2.276b+2.577b^2} & b \lt 1.6 \\
          1                       & \text{otherwise}
        \end{cases} \\
        b &= (a \tan{\theta_v})^{-1}\\
        \chi^+(c) &=
        \begin{cases}
          1 & c > 0 \\
          0 & c \le 0
        \end{cases} \\
      \end{align*}
      where \(\theta_v\) is the angle between the surface normal \(\bold{n}\)
      and the \(\omega_v\) argument of \(G_1\).</p>      

      <h4>Sampling</h4>

      <p>In this part you will generate samples according to the following density function:
      \[
        k_s ~ D(\omega_h) \cos{\theta_h} ~ J_h + (1-k_s) \frac{\cos{\theta_o}}{\pi}
      \]
      where \(J_h = (4 (\omega_h \cdot \omega_o))^{-1}\) is the Jacobian of the half direction mapping discussed in class.  Choose whether to sample the diffuse or the specular component based on the value of \(k_s\). In the first case, follow the recipe from the slides, by sampling a normal from the microfacet distribution and reflecting the incident direction using this normal.  In the latter case, generate a cosine-weighted direction on the sphere using the same method as the model in the <code>wakame.bsdf.Diffuse</code> class.</p>

      <h4>Validation</h4>

      <p>You can experiment with the warptest GUI and visualize your implemented BRDF. Pass all the \(\chi^2\) and t-tests for the Microfacet BRDF found in <tt>data/pa3/tests</tt>: 
        <ul> 
          <li><tt>chi2test-microfacet.xml</tt>, </li>
          <li><tt>ttest-microfacet.xml</tt></li>
        </ul>
      Note that the <tt>WarpTest</tt> application also contains a \(\chi^2\) test, but this is just to facilitate debugging and visualization; the XML files are the real validation benchmark.
      </p>
      
      <p>
        Now that the microfacet BRDF has been implemented, you can render the following scenes:
        <ul>                    
          <li><tt>veach_mi/veach_ems.xml</tt></li>
          <li><tt>veach_mi/veach_mats.xml</tt></li>
        </ul>
      </p>

      <table class="table table-bordered">
        <tr>
          <td align="center" valign="center"><a href="images/pa2/veach_ems_256spp.png"><img src="images/pa2/veach_ems_256spp.png" height="300"/></a></td>
          <td align="center" valign="center"><a href="images/pa2/veach_mats_256spp.png"><img src="images/pa2/veach_mats_256spp.png" height="300"/></a></td>          
        </tr>
        <tr>
          <td align="center"><tt>veach_mi/veach_ems.xml</tt></td>
          <td align="center"><tt>veach_mi/veach_mats.xml</tt></td>          
        </tr>
      </table>

      <a href="#" id="p3"></a>
      <h2>Part 3: Multiple Importance Sampling</h2>

      <h3>Integrator Implementation</h3>

      <p>In this part we will implement another direct illumination integrator (<tt>direct_mis</tt>) This integrator will combine both sampling strategies for computing direct illumination by using multiple importance sampling with the balance heuristic. At your first camera ray intersection you will sample using both strategies: sampling the emitters and sampling the corresponding BSDF. You will then combine the two estimates by using the following expression:
      \[
          L_o (p,\omega_o) \approx \frac{1}{N} \sum^N \left(
            L_e(p,\omega_o) + w_\text{em}\frac{\integrand(p,\omega_o,\omega_{i,e}) }{\text{pdf}_\text{em}(\omega_{i,e})}

          + w_\text{mat} \frac{\integrand(p,\omega_o,\omega_{i,m}) }{\text{pdf}_\text{mat}(\omega_{i,m})}
          \right)\\
          w_\text{em} = \frac{\text{pdf}_\text{em}(\omega_{i,e}) }{\text{pdf}_{\text{em}}(\omega_{i,e})+\text{pdf}_{\text{mat}}(\omega_{i,e})}, ~ ~
          w_\text{mat} = \frac{\text{pdf}_\text{mat}(\omega_{i,m}) }{\text{pdf}_{\text{em}}(\omega_{i,m})+\text{pdf}_{\text{mat}}(\omega_{i,m})}
      \]
      For this to work, it is <em>crucial</em> that the probability densities are expressed in terms of the same units (so either density per unit solid angle, or density per unit area). Mixing units will lead to suboptimal weights.</p>

      <h3>Validation</h3>
      <p>
      Pass the <tt>direct_mis</tt> related t-tests found in <tt>data/pa2/tests</tt>: 
      <ul>
        <li>last 4 tests in <tt>test-distant.xml</tt>,</li>
        <li>last 5 tests in <tt>test-mesh.xml</tt>,</li>
        <li>last 2 tests in <tt>test-mesh-furnace.xml</tt> </li>
      </ul>
      Mention in your report if there any errors reported.
      </p>
      <p>
      Using <tt>direct_mis</tt> render the following scenes found in <tt>data/pa2</tt> : 
      <ul>
        <li><tt>sphere/sphere_ao_mis.xml</tt>, </li>
        <li><tt>sphere/sphere_side_mis.xml</tt>, </li>
        <li><tt>odyssey/odyssey_mis.xml</tt>, </li>
        <li><tt>veach_mi/veach_mis.xml</tt> </li>        
      </ul>
      </p>      
      <p>Show a 3-way comparison for each of the 4 scenes in your report. For each scene compare your 3 integrators (<tt>direct_ems</tt>, <tt>direct_mats</tt>, <tt>direct_mis</tt>) with the reference MIS rendering.</p>

      <table class="table table-bordered">
        <tr>
          <td align="center" valign="center"><a href="images/pa2/sphere_ao_mis_128spp.png"><img src="images/pa2/sphere_ao_mis_128spp.png" height="300"/></a></td>
          <td align="center" valign="center"><a href="images/pa2/sphere_side_mis_128spp.png"><img src="images/pa2/sphere_side_mis_128spp.png" height="300"/></a></td>          
        </tr>
        <tr>
          <td align="center"><tt>sphere/sphere_ao_mis.xml</tt></td>
          <td align="center"><tt>sphere/sphere_side_mis.xml</tt></td>          
        </tr>
        <tr>
          <td align="center" valign="center"><a href="images/pa2/odyssey_mis_32spp.png"><img src="images/pa2/odyssey_mis_32spp.png" height="250"/></a></td>
          <td align="center" valign="center"><a href="images/pa2/veach_mis_128spp.png"><img src="images/pa2/veach_mis_128spp.png" height="250"/></a></td>          
        </tr>
        <tr>
          <td align="center"><tt>odyssey/odyssey_mis.xml</tt></td>
          <td align="center"><tt>veach_mi/veach_mis.xml</tt></td>          
        </tr>
      </table>   

      <a href="#" id="p4"></a>
      <h2>Part 4: Path Tracing</h2>

      <h3><tt>path_mats</tt> Implementation</h3>

      <p>In this part you will implement a naive global illumination path tracing integrator (<tt>path_mats</tt>) which is an estimator of the rendering equation using only BSDF sampling; paths only contribute when they randomly hit a light source.  Your <tt>direct_mats</tt> integrator should be a great start: you just have to add the recursion.  Use the Russian roulette technique as a path termination criterion to avoid infinite recursion.</p>      

      <h3><tt>path_mis</tt> implementation</h3>

      <p>In this part you will implement a more advanced path tracer (<tt>path_mis</tt>) which solves the rendering equation by performing both BSDF sampling and emitter sampling and combining the two strategies using multiple importance sampling as discussed in class. Use the Russian roulette technique as a path termination criterion to avoid infinite recursion.</p>

      <h3>Validation</h3>
      <p>
        Pass the related tests found in <tt>data/pa2/tests</tt>:
        <ul>
          <li> <tt>test-direct.xml</tt>, </li>
          <li> <tt>test-furnace.xml</tt> </li>
        </ul>
      </p>
      <p>
        Using <tt>path_mats</tt> and <tt>path_mis</tt> render the following scenes found in <tt>data/pa2</tt> :
        <ul>
          <li><tt>cbox/cbox_mats.xml</tt>, </li>
          <li><tt>cbox/cbox_mis.xml</tt>, </li>
          <li><tt>table/table_mats.xml</tt>, </li>
          <li><tt>table/table_mis.xml</tt>, </li>
        </ul>
        In your report provide two 3-way comparisons of your rendering results and the <tt>mis</tt> reference.
      </p>

      <table class="table table-bordered">
        <tr>
          <td align="center" valign="center"><a href="images/pa2/cbox_path_mats_512spp.png"><img src="images/pa2/cbox_path_mats_512spp.png" height="300"/></a></td>
          <td align="center" valign="center"><a href="images/pa2/cbox_path_mis_512spp.png"><img src="images/pa2/cbox_path_mis_512spp.png" height="300"/></a></td>          
        </tr>
        <tr>
          <td align="center"><tt>cbox/cbox_mats.xml</tt></td>
          <td align="center"><tt>cbox/cbox_mis.xml</tt></td>          
        </tr>
        <tr>
          <td align="center" valign="center"><a href="images/pa2/table_path_mats_512spp_0p01roulette.png"><img src="images/pa2/table_path_mats_512spp_0p01roulette.png" height="250"/></a></td>
          <td align="center" valign="center"><a href="images/pa2/table_path_mis_512spp_0p01roulette.png"><img src="images/pa2/table_path_mis_512spp_0p01roulette.png" height="250"/></a></td>          
        </tr>
        <tr>
          <td align="center"><tt>table/table_mats.xml</tt></td>
          <td align="center"><tt>table/table_mis.xml</tt></td>          
        </tr>
      </table>   
    </div> <!-- /container -->

    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="js/jquery.js"></script>
    <script src="js/bootstrap.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
      });
    </script>
    <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
    <script type="text/javascript" src="js/google-code-prettify/prettify.js"></script>
  </body>
</html>
